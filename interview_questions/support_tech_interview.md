# Вопросы и ответы к собеседованию на инженера по сопровождению ПО (с элементами SRE/DevOps)

#### **1. Расскажите о вашем опыте работы с инструментами SRE и DevOps. Какие задачи вы решали?**  
**Ответ:**  
Я участвовал в проектах по автоматизации развертывания инфраструктуры с использованием Terraform и Ansible. Например, настраивал CI/CD-пайплайны в GitLab для автоматического деплоя микросервисов в Kubernetes. Также внедрял мониторинг на базе Prometheus и Grafana, чтобы отслеживать метрики серверов и приложений. В рамках SRE работал над улучшением надежности системы: уменьшал время восстановления (MTTR) за счет автоматизации рутинных задач и улучшения документации.

---

#### **2. Как вы внедряли обновления серверов? Какие инструменты использовали, и как применяли Ansible?**  
**Ответ:**  
Для обновления серверов я использовал Ansible для автоматизации. Например, создавал плейбуки, которые выполняли:  
- Обновление пакетов через `apt`/`yum`.  
- Перезапуск сервисов.  
- Проверку состояния системы после обновления.  
Также использовал Ansible для настройки конфигураций (например, обновление конфигов Nginx) и массового развертывания обновлений на сотни серверов. Для минимизации downtime применял постепенное развертывание (canary deployments) через интеграцию с Kubernetes.

---

#### **3. Приведите пример решения инцидента: база PostgreSQL «упала». Как вы действовали?**  
**Ответ:**  
Однажды мониторинг алертнул о недоступности PostgreSQL. Я:  
1. Проверил статус кластера через `systemctl status postgresql` и логи (`journalctl`).  
2. Обнаружил, что диск переполнен из-за неудаленных WAL-файлов.  
3. Очистил старые WAL, перезапустил кластер.  
4. Настроил автоматическую ротацию WAL через `archive_mode` и `archive_command`.  
5. Добавил алерт в Prometheus на проверку свободного места на диске.  

---

#### **4. Как вы настраивали мониторинг с Prometheus и Grafana? Приведите примеры.**  
**Ответ:**  
Для мониторинга я:  
- Устанавливал Node Exporter для сбора метрик серверов.  
- Использовал PostgreSQL Exporter для отслеживания состояния БД.  
- Настроил Prometheus для сбора данных и Grafana для визуализации.  
Пример дашборда:  
- Графики CPU/памяти, использование диска, время ответа HTTP-запросов.  
- Алерты на падение сервисов (например, если Nginx не отвечает 5 минут).  

---

#### **5. Какие обязанности, кроме технических, входили в вашу роль? Как вы решали кредитные заявки?**  
**Ответ:**  
Кроме технической поддержки, я:  
- Анализировал кредитные заявки через SQL-запросы к БД (например, проверял статусы транзакций).  
- Использовал ELK-стек для поиска ошибок в логах (например, сбои при обработке заявок).  
- Взаимодействовал с API внутренних сервисов через Postman или кастомные скрипты для обновления статусов заявок.  
- В Kubernetes проверял статус подов и перезапускал проблемные контейнеры.  

---

#### **6. Расскажите о вашем опыте работы с Kubernetes. Что обновляли, как мониторили?**  
**Ответ:**  
Я работал с Kubernetes:  
- Обновлял кластеры с помощью `kubeadm` и Helm-чартов.  
- Мониторил через Prometheus и Grafana (метрики CPU/памяти подов, статус деплойментов).  
- Автоматизировал деплой приложений через Argo CD.  
- Решал проблемы: например, устранял CrashLoopBackOff, анализируя логи контейнеров (`kubectl logs`), и пересоздавал зависшие поды.  

---

#### **7. Как вы управляли инцидентами с Nginx? Пример решения проблемы.**  
**Ответ:**  
При падении Nginx:  
1. Проверял статус сервиса: `systemctl status nginx`.  
2. Анализировал конфиг на ошибки: `nginx -t`.  
3. Если проблема в перегруженности сервера — добавлял upstream-серверы через настройку балансировки.  
4. Для профилактики настраивал лимиты запросов через `limit_req` и мониторил ошибки 5xx в Prometheus.  

---

#### **8. Какие инструменты использовали для работы с логами? Как интегрировали ELK?**  
**Ответ:**  
Я настраивал ELK-стек:  
- Собирал логи через Filebeat.  
- Парсил их в Logstash.  
- Хранил в Elasticsearch.  
- Визуализировал в Kibana (например, создавал дашборды для отслеживания ошибок в кредитных заявках).  
Это помогало быстро находить root cause, например, сбоев при обработке платежей.  

---

#### **9. Как вы обеспечивали надежность системы (SRE-практики)?**  
**Ответ:**  
Я внедрял:  
- SLO/SLI для ключевых сервисов (например, время ответа API ≤ 500 мс).  
- Автоматические резервные копии БД через `pg_dump` и скрипты на Bash.  
- Ротацию критических задач (on-call дежурства).  
- Post-mortem-анализ после инцидентов с фиксацией улучшений.  

---

#### **10. Как вы решали проблемы с производительностью приложений?**  
**Ответ:**  
Например, при медленных запросах к БД:  
1. Использовал `EXPLAIN` в PostgreSQL для анализа запросов.  
2. Добавлял индексы или переписывал запросы.  
3. Настройкал пул соединений через PgBouncer.  
4. Масштабировал кластер Kubernetes, увеличивая реплики подов.  

---

#### **11. Расскажите о вашем опыте с CI/CD. Какие инструменты использовали?**  
**Ответ:**  
Я настраивал пайплайны в GitLab CI:  
- Сборка Docker-образов.  
- Тестирование через pytest.  
- Деплой в Kubernetes с помощью Helm.  
Также использовал Argo CD для GitOps-подхода.  

---

#### **12. Как вы работали с инцидентами, связанными с сетью? Пример.**  
**Ответ:**  
При проблемах с доступностью сервиса:  
1. Проверял доступность через `curl` и `telnet`.  
2. Анализировал правила фаервола (`iptables`, Security Groups).  
3. Использовал `tcpdump` для захвата трафика.  
4. Например, восстановил работу Nginx, обновив настройки проксирования.  

---

#### **13. Как вы управляли конфигурациями серверов?**  
**Ответ:**  
Использовал Ansible для управления конфигами:  
- Хранил их в Git.  
- Автоматически применял изменения через плейбуки.  
- Проверял целостность конфигов с помощью тестов в Molecule.  

---

#### **14. Как вы решали проблемы с памятью в приложениях?**  
**Ответ:**  
Например, при OOM-ошибках в Java-приложении:  
1. Анализировал метрики в Prometheus/Grafana.  
2. Увеличивал лимиты памяти в Kubernetes.  
3. Оптимизировал код (например, уменьшал использование кучи).  

---

#### **15. Как вы взаимодействовали с командой разработки?**  
**Ответ:**  
- Участвовал в daily standup-митингах.  
- Создавал баг-репорты в Jira с детальным описанием проблем.  
- Предлагал улучшения кода (например, добавление логов для упрощения диагностики).  

---

#### **16. Как вы обеспечивали безопасность инфраструктуры?**  
**Ответ:**  
- Регулярно обновлял пакеты и закрывал уязвимости (CVE).  
- Настройвал TLS для сервисов (Let’s Encrypt).  
- Проверял права доступа в Kubernetes (RBAC).  

---

#### **17. Как вы тестировали обновления перед деплоем?**  
**Ответ:**  
- Использовал staging-окружение, идентичное production.  
- Проводил нагрузочное тестирование через JMeter.  
- Проверял бэкапы перед обновлениями БД.  

---

#### **18. Как вы решали проблемы с репликацией в PostgreSQL?**  
**Ответ:**  
При сбое репликации:  
1. Проверял статус реплики через `pg_stat_replication`.  
2. Восстанавливал WAL-файлы из архива.  
3. Перенастраивал репликацию через `pg_basebackup`.  

---

#### **19. Как вы работали с алертами из мониторинга?**  
**Ответ:**  
- Настройкал алерты в Prometheus на критические метрики (CPU > 90%, 5xx ошибки).  
- Интегрировал оповещения в Telegram/Email.  
- При срабатывании алерта анализировал root cause через Grafana и логи.  

---

#### **20. Какие навыки вы считаете основными для инженера по сопровождению?**  
**Ответ:**  
- Глубокое понимание инфраструктуры (Linux, сети, БД).  
- Умение быстро анализировать логи и метрики.  
- Навыки автоматизации (Ansible, Bash, Terraform).  
- Коммуникация с клиентами и командами.  
- Знание принципов SRE (SLO, постмортемы).

---

## Расскажите о мониторинге в отделе? Как мониторилась инфраструктура и чем? Приведите примеры?

### **1. Как стек мониторинга на основе Prometheus использовался в вашей работе?**
**Пример ответа:**  
"Стек мониторинга на основе Prometheus использовался для централизованного мониторинга инфраструктуры, приложений и бизнес-метрик. Мы собирали данные с серверов (через Node Exporter), веб-серверов (Nginx Exporter), процессов (Process Exporter), баз данных (PostgreSQL Exporter) и других источников. Эти данные анализировались в Prometheus, визуализировались в Grafana, отправлялись через Alertmanager для уведомлений, а также использовались Federation и Pushgateway для специфических задач."

---

### **2. Кому вы предоставляли доступ к мониторингу и устанавливали экспортеры каким командам?**
**Пример ответа:**  
"Я предоставлял доступ к мониторингу следующим командам:
- **Команды DevOps/SRE:** для отслеживания состояния инфраструктуры и приложений.
- **Команды разработчиков:** для анализа производительности их сервисов.
- **Бизнес-аналитики:** для отслеживания ключевых бизнес-метрик (например, количество заказов или активных пользователей).
- **Менеджеры проектов:** для получения обзора состояния системы.

Экспортеры устанавливались на серверы, где работали соответствующие сервисы. Например:
- **Node Exporter** — для серверов.
- **Nginx Exporter** — для веб-серверов.
- **Process Exporter** — для мониторинга конкретных процессов.
- **Custom Exporter** — для специфических метрик.
- **PostgreSQL Exporter** — для баз данных.
- **Blackbox Exporter** — для проверки доступности сервисов.
- **Pushgateway** — для batch-задач и CI/CD пайплайнов."

---

### **3. Пример 10 кейсов использования мониторинга и их реализация**

#### **Кейс 1: Мониторинг высокой нагрузки CPU**
**Описание проблемы:**  
"Один из наших серверов начал показывать высокую нагрузку CPU, что приводило к замедлению работы приложения."

**Решение:**  
1. Настроил сбор метрик с помощью **Node Exporter**:  
   ```yaml
   scrape_configs:
     - job_name: 'node'
       static_configs:
         - targets: ['localhost:9100']
   ```
2. Создал алерт в Prometheus:  
   ```yaml
   groups:
     - name: cpu_alerts
       rules:
         - alert: HighCpuUsage
           expr: 100 - (avg by (instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 85
           for: 5m
           labels:
             severity: critical
           annotations:
             summary: "High CPU usage on {{ $labels.instance }}"
             description: "CPU usage is above 85% for more than 5 minutes."
   ```

**Результат:**  
"Мы быстро обнаружили проблему и оптимизировали код приложения, что снизило нагрузку на CPU."

---

#### **Кейс 2: Мониторинг доступности веб-сервиса**
**Описание проблемы:**  
"Один из наших веб-сервисов стал недоступен для пользователей."

**Решение:**  
1. Настроил **Blackbox Exporter** для проверки HTTP-статуса:  
   ```yaml
   scrape_configs:
     - job_name: 'blackbox'
       metrics_path: /probe
       params:
         module: [http_2xx]
       static_configs:
         - targets:
             - http://example.com
       relabel_configs:
         - source_labels: [__address__]
           target_label: __param_target
         - source_labels: [__param_target]
           target_label: instance
         - target_label: __address__
           replacement: localhost:9115
   ```
2. Создал алерт в Prometheus:  
   ```yaml
   groups:
     - name: service_availability
       rules:
         - alert: ServiceDown
           expr: probe_success == 0
           for: 2m
           labels:
             severity: critical
           annotations:
             summary: "Service {{ $labels.instance }} is down"
             description: "The service has been unavailable for more than 2 minutes."
   ```

**Результат:**  
"Мы получили уведомление о проблеме и восстановили работу сервиса за несколько минут."

---

#### **Кейс 3: Мониторинг репликации PostgreSQL**
**Описание проблемы:**  
"Мы заметили задержки в репликации PostgreSQL, что могло привести к потере данных."

**Решение:**  
1. Настроил **PostgreSQL Exporter** для сбора метрик репликации:  
   ```yaml
   scrape_configs:
     - job_name: 'postgres'
       static_configs:
         - targets: ['localhost:9187']
   ```
2. Создал алерт в Prometheus:  
   ```yaml
   groups:
     - name: replication_lag
       rules:
         - alert: ReplicationLag
           expr: pg_replication_lag_seconds > 30
           for: 5m
           labels:
             severity: warning
           annotations:
             summary: "Replication lag detected on {{ $labels.instance }}"
             description: "Replication lag is above 30 seconds for more than 5 minutes."
   ```

**Результат:**  
"Мы обнаружили проблему с сетевым подключением между мастером и репликой и устранили её до того, как она повлияла на пользователей."

---

#### **Кейс 4: Мониторинг Nginx**
**Описание проблемы:**  
"Нужно было отслеживать производительность Nginx (количество запросов, ошибки)."

**Решение:**  
1. Установил **Nginx Exporter** и настроил сбор метрик:  
   ```yaml
   scrape_configs:
     - job_name: 'nginx'
       static_configs:
         - targets: ['localhost:9113']
   ```
2. Создал дашборд в Grafana для анализа метрик.

**Результат:**  
"Мы смогли оперативно реагировать на падение производительности Nginx."

---

#### **Кейс 5: Мониторинг процессов**
**Описание проблемы:**  
"Нужно было отслеживать потребление ресурсов конкретными процессами."

**Решение:**  
1. Настроил **Process Exporter**:  
   ```yaml
   process_names:
     - name: "{{.Comm}}"
       cmdline:
         - "my-app"
   ```
2. Добавил алерты в Prometheus.

**Результат:**  
"Мы обнаружили утечку памяти в одном из процессов и исправили её."

---

#### **Кейс 6: Мониторинг бизнес-метрик**
**Описание проблемы:**  
"Нужно было отслеживать количество заказов в системе."

**Решение:**  
1. Написал **Custom Exporter**, который собирал метрики из базы данных.  
2. Настроил Prometheus для сбора этих метрик.

**Результат:**  
"Мы смогли анализировать тренды и прогнозировать нагрузку."

---

#### **Кейс 7: Мониторинг batch-задач**
**Описание проблемы:**  
"Batch-задачи завершались до того, как Prometheus мог их скрейпнуть."

**Решение:**  
1. Настроил **Pushgateway** для приема метрик:  
   ```bash
   echo "batch_job_duration_seconds 42" | curl --data-binary @- http://pushgateway:9091/metrics/job/batch_job
   ```
2. Настроил Prometheus для сбора данных с Pushgateway.

**Результат:**  
"Мы смогли отслеживать продолжительность выполнения batch-задач."

---

#### **Кейс 8: Централизованный мониторинг нескольких дата-центров**
**Описание проблемы:**  
"У нас было несколько дата-центров, и нужно было объединить метрики."

**Решение:**  
1. Настроил **Prometheus Federation**:  
   ```yaml
   scrape_configs:
     - job_name: 'federate'
       honor_labels: true
       metrics_path: '/federate'
       params:
         match[]:
           - '{job="node"}'
       static_configs:
         - targets:
             - 'prometheus-dc1:9090'
             - 'prometheus-dc2:9090'
   ```

**Результат:**  
"Мы получили единый обзор метрик из всех дата-центров."

---

#### **Кейс 9: Мониторинг CI/CD пайплайнов**
**Описание проблемы:**  
"Нужно было отслеживать время выполнения CI/CD пайплайнов."

**Решение:**  
1. Добавил шаг в CI/CD пайплайн для отправки метрик в **Pushgateway**:  
   ```bash
   echo "ci_pipeline_duration_seconds $(date +%s)" | curl --data-binary @- http://pushgateway:9091/metrics/job/ci_pipeline
   ```
2. Настроил Prometheus для сбора данных с Pushgateway.

**Результат:**  
"Мы смогли анализировать время выполнения CI/CD пайплайнов."

---

#### **Кейс 10: Интеграция с Alertmanager**
**Описание проблемы:**  
"Нужно было настроить уведомления о критических событиях."

**Решение:**  
1. Настроил **Alertmanager** для отправки уведомлений в Slack:  
   ```yaml
   route:
     receiver: slack-notifications
   receivers:
     - name: slack-notifications
       slack_configs:
         - api_url: 'https://hooks.slack.com/services/...'
           channel: '#alerts'
   ```

**Результат:**  
"Команды получали уведомления о проблемах в режиме реального времени."

---

### **4. Какие каверзные вопросы могут возникнуть и как на них ответить?**

#### **Вопрос: Как решать проблемы с производительностью Prometheus?**
**Ответ:**  
"Если возникали проблемы с производительностью, я:
- Оптимизировал запросы PromQL, избегая сложных агрегаций.
- Увеличивал ресурсы сервера (CPU, RAM).
- Настроил retention period для хранения данных (например, `retention: 15d`)."

#### **Вопрос: Как обеспечивать безопасность стека мониторинга?**
**Ответ:**  
"Я ограничивал доступ через firewall, настраивал reverse proxy (Nginx) с аутентификацией и размещал все компоненты только внутри закрытой сети."


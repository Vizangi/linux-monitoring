# Легенда инженера по сопровождению ПО, работающего в отделе мониторинга

1. В первом приближении в самом начале репозитория `linux-monitoring` с данным разделом (легенда) знакомимся поверхностно, чтобы понять объемы и масштабы обучения, но при этом стараемся сразу выучить легенду, чтобы она хорошо отложилась для будущих собеседований.
2. Во втором приближении после полного завершения данного репозитория `linux-monitoring` начинаем полностью учить все вопросы из данного раздела (легенда):
   - Общие вопросы, разбиение собеседования на последовательные этапы и вопросы работодателя - [полностью учим здесь](https://teletype.in/@lamjob/sPRL_XpiLkV) во втором приближении после прохождения практики и теории всего репозитория `linux-monitoring`
   - Далее учим [дополнительный пул вопросов](https://teletype.in/@lamjob/dzsUuHD-XGj) во втором приближении после прохождения практики и теории всего репозитория `linux-monitoring`

_Учим не досконально, а поэтапно, не нужно зацикливаться на всех вопросах и темах.

На первых этапах у вас должно быть чёткое понимание каждого инструмента по вашему стеку, зачем он нужен и что из себя представляет.

При этом если в стеке указан Teamcity или Nginx - это не значит, что вы должны знать, как он работает полностью технически и досконально, нужно подстраиваться под каждый вопрос и говорить о том, что Teamcity вы использовали совместно с администраторами для выкатки релизов, настраивали балансировку Nginx по алгоритму round-robin, вы только правили конфиг к примеру и всё, этого будет достаточно - и так с каждым инструментом и вопросом.

На собеседовании мы не говорим об указанном стеке в резюме, что мы с ним не работали, мы говорим по алгоритму указанному выше - то есть мы всегда всё знаем, мы всегда работали, мы выкатывали, пусть даже поверхностно, но в составе разработчиков, DevOps или администраторов._

---

## В этом разделе я сделал специально вбросы от собеседующих буквально в собес: в ваш рассказ о себе, об отделе, о распорядке дня
_То есть мы учим легенду и как будто бы присутствуем на одном из собеседований. А также я понимаю, что это может быть лишь один из вариантов собеседования, ведь все они разные, но зато это уникальный и очень удобный смешанный формат._

### 1. **Общая информация о работе и отделе**
Я работаю инженером по сопровождению ПО в отделе мониторинга. Наш отдел отвечает за обеспечение стабильной работы критически важных сервисов компании, а также за своевременное выявление и устранение инцидентов. Мы активно используем современные инструменты для мониторинга, автоматизации и управления инфраструктурой. В нашем стеке используются:
Здесь идёт перечисление инструментов и ПО [из раздела номер 3 по вашему стеку](https://github.com/lamjob1993/linux-monitoring/blob/main/Introduction_monitoring/legend_support_engineer.md#3-%D1%81%D1%82%D0%B5%D0%BA-%D0%BE%D1%82%D0%B4%D0%B5%D0%BB%D0%B0) - перечисляем обязательно, чтобы собеседующие поняли, что вы с этими инструментами работаете повседневно.

**Моя основная задача** — поддерживать работоспособность всех систем (дебаг сервисов), разрабатывать мониторинг (дашборды + установка экспортеров), решать возникающие инциденты, внедрять релизы (об этом будет ниже) и следить за качеством работы серверов и приложений (ежедневная аналитика мониторинга).

В нашем отделе работают:
- Всего x10 человек исполнителей + x2 руководителя = x12:
   - Тимлид (архитектор) и продакт (основной руководитель проекта по сопровождению)
- x2 DevOps инженера на уровне middle
- x1 Senior Go-разработчик
- x1 Middle Go-разработчик
- x3 Middle инженера по мониторингу
- x3 Junior инженера по сопровождению

Если будут спрашивать на собеседовании о каких-то сложных кейсах и задачах, и если вы не знаете как отвечать, то можно ссылаться на команду, на мидлов и сениоров, что сложные задачи решали совместно с ними (с DevOps или с более старшими по рангу, либо вообще спрашивали советы у тимлида - и это нормально). 

#### 1. Расскажите о вашем опыте работы с Linux-администраторами?
"В моей текущей роли я тесно взаимодействую с командой администраторов Linux (CentOS/Debian). Мы совместно решаем задачи по обновлению ОС и внедрениям. Например, недавно мы автоматизировали процесс обновления критических пакетов через Ansible, что позволило сократить время обслуживания серверов на 40%."

#### 2. Как вы взаимодействуете с разработчиками?
"Ежедневно работаю с разработчиками над решением инцидентов в production. Через CI/CD-пайплайны TeamCity мы внедряем новые релизы. Важным аспектом является анализ медленных запросов к PostgreSQL - совместно оптимизируем запросы и индексы (идексы нужны для оптимизации запросов, вкратце с вами пробежимся по индексам на курсе). Также регулярно проводим постмортем-анализ инцидентов для предотвращения повторений, кстати, страничку постмортема в Confluence написал я."

#### 3. Опишите опыт работы с аналитиками?
"Для аналитиков я создаю специальные дашборды в Grafana, включающие ключевые метрики производительности системы. Мы вместе анализируем тренды использования ресурсов и время реакции на инциденты. Например, благодаря таким анализам мы оптимизировали использование RAM на 25% в peak-time."

#### 4. Как проходит взаимодействие со смежными командами?
"Участвую в еженедельных встречах, где координирую действия между командами DevOps, разработчиков и администраторов. Внедрили общую систему мониторинга через Prometheus, которая позволяет всем командам видеть актуальное состояние инфраструктуры. При аварийных ситуациях организуем Zoom встречи для быстрого решения проблем."

"Участвую в еженедельной встрече по презентации мониторинга нашей платформы. Мы разрабатываем мониторинг для команд от дашбордов Grafana до оптимизации метрик Prometheus. Встреча проходит для команд нашего департамента. Я презентую в рельном времени, как работает связка мониторинга Grafana + Prometheus + Node Exporter, как работают метрики, пишу простые формулы на языке PromQL, после чего мне задают вопросы. Заинтересованные команды могут заказать у нас мониторинг через заявку в Jira."

---

### 2. **Распорядок дня**
- Каждый день начинается со встречи (с дейлика: daily stand-up) с начальством (руководитель основной и тимлид) и командой ([Корпорация: Инструменты корпорации](https://teletype.in/@lamjob/JHJK3FHMdS5)).
- На этой встрече мы обсуждаем текущие инциденты, задачи на день, а также прогресс по внедрению новых релизов.
- Тимлид ведет опрос каждого инженера и назначает новые задачи, спрашивает о текущих активностях и задачах подробно каждого (переодически тимлида перебивает главный рук и вбрасывает свои вопросы и реплики).
- Дейлик идет от 30 минут до часа - дальше все расходятся: команда частично на фулл удаленке и частично на гибриде (частично Москва, частично Нижний, частично Самара).
- После дейлика я проверяю дашборды в Grafana, чтобы убедиться, что все метрики в пределах нормы.
- Если есть какие-либо аномалии или инциденты, я сразу же начинаю их расследование.

**Основные задачи дня:**
- Мониторинг состояния систем через Prometheus и Grafana:
   - Обращаю внимание на анамалии, если есть: просадка трафика, перезапуск подов (контейнеров), проверка бизнесовых ошибок (это те ошибки которые выдают наши приложения, к примеру, на кредитном конвейере), проверка сервисов, написанных на Java/Kotlin)).
   - Куда смотришь в Grafana (на какие имменно дашборды)?
      - Смотрю на дашборды:
         - Nginx (проверяю статус нашего сервера балансировки)
         - Node Exporter по нашим серверам (смотрю загруженность по железу)
         - Postgres Exporter (смотрю на состояние базы, на количество активных пользователей, смотрю аптайм)
         - Blackbox Exporter (смотрю, когда протухнут сертификаты и когда их нужно будет перевыпустить)
         - Kubernetes (смотрю на рестарт подов по нашим приложениям, смотрю на трафик, на нагрузку подов)
      - Кто и как поднимал экспортеры и дашборды?
         - Я поднимал через юнит-сервисы все экспортеры и рисовал кастомные дашборды на основе официальных с сайта Grafana Lab.
            - Я создавал папку Grafana, писал название дашборда, к примеру, если это Monitoring Nginx, то я наполнял дашборд метриками, которые снимал с помощью Nginx Exporter, который стоял на сервере с Nginx.
               - Как снимал?
                  - Nginx Exporter был указан, как таргет (цель) в конфиге Prometheus и Prometheus скрейпал с него метрики
                  - Далее я прописывал Prometheus Data Sourse в Grafana и получал доступ к метрикам
                  - Рисовал с помощью формул на основе PromQL, какие-то кастомные, какие-то оригинальные копировал с дашборда Nginx
               - А что именно рисовали? Какие виджеты?
                  - Рисовал виджеты [по золотым сигналам](https://github.com/lamjob1993/linux-monitoring/blob/main/prometheus/beginning/4.%20%D0%A7%D0%B5%D1%82%D1%8B%D1%80%D0%B5%20%D0%B7%D0%BE%D0%BB%D0%BE%D1%82%D1%8B%D1%85%20%D1%81%D0%B8%D0%B3%D0%BD%D0%B0%D0%BB%D0%B0%20(Four%20Golden%20Signals).md):
                     - Соотношение HTTP успешных запросов к неуспешным
                     - Состояние трафика сервера, Upstream, Network
                     - Состояние: CPU Usage, Memory Usage
                  - А как вывести монотонно возрастающий счетчик?
                     - `rate(name_metric{}[1m])` или `irate(name_metric{}[1m])`
                  - А как вывести сумму ошибок?
                     - `sum (name_metric)`
                  - А как группировку по суммам всех ошибок?
                     - `sum by (status) (name_metric)`
                  - А как сделать группировку по лейблам?
                     - `group by (status, instance) (name_metric)`
- Решение инцидентов, которые могут возникнуть в процессе работы:
   - Я собираю или свою встречу по ссылке в Zoom (для Сбера - это только Jazz или просто говорим, что по "нашей ссылке") или идем в аварийку (по ссылке) и решаем совместно инцидент:
      - Кто собирал?
      - Я собирал, я делал рассылку, я пинговал, как в ТГ, так и в корпоративном мессенджере.
   - Как решали инцидент? Этапы решения?
      - Сначала я пошел смотреть на мониторинг и увидел (на дашборде Kubernetes), что был рестарт подов по нашему сервису, далее пошел смотреть на этот сервис в систему логирования OpenSearch (это аналог ELK), далее открываю JSON лог и вижу 502 или 503 ошибку (они будут в 90% случаев у вас) - ошибка на сервере (на каком сервере? - на Nginx), от нас поступает API запрос (что такое API? - [Ответ](https://teletype.in/@lamjob/xnxhxKyYr93)) на Nginx-сервер, и сервер выдает ответ 502 или 503 - а это что такое:
         - `Ошибка 503 (Service Unavailable)` сообщает, что сервер временно недоступен и не может обработать запрос.
         - `Ошибка 502 (Bad Gateway)` означает, что сервер не получил ответ от другого сервера. Возможно, сервер, где хранится база, перестал работать или данные были случайно удалены.
      - Сначала решаю инцидент своими силами:
         - Провожу расследование (дашборд Grafana -> логи OpenSearch -> дёргаю за ручку API (о ручке ниже, ручка - это адрес `/path/to/api`) -> перезапуск сервиса в крайнем случае)
         - Проверяю API запрос и понимаю, что запрос неверный:
            - Почему неверный? Я сверил с актуальной документацией API запрос с запросом API. И понял, что один из разработчиков совершил синтаксическую ошибку в коде при раскатке (через Teamcity) и адрес API побился
            - А какую роль играет API в вашем приложении?
               - У нас API поддерживает каждое Java приложение, это набор инструкций для обмена данными между приложениями
               - В нашем случае есть API, отвечающий за документы, за биллинг, за кредитный конвейер и т.д:
                  - За каждый API можно дёрнуть и получить готовый JSON, либо восстановить работу приложения (отвечаем, что делали по инструкции в Confluence и собеседующий отстанет, но не выдавайте инструкцию явно, оставляем на последок)
               - А как дёргаете? Каким запросом ручку?
               - `GET`
               - А чем дёргаете? Каким приложением?
                  - OpenLens (GUI для Kubernetes/K8S - визуализация кластера)
                  - Postman (это программа для тестирования API (Application Programming Interface) и REST, упрощающая процесс отладки и тестирования кода)
                  - Вручную из контейнера внутри пода (Kubernetes)
               - Если будет глобальный допрос - на какие кнопки нажимали (OpenLens, Postman и т.д)?
                  - Отвечаем, что по инструкции в Confluence, потому что все приложения разные и у вас на конвейере их много и они микросервисные, и что на каждую ручку свой запрос
      - Далее если все-таки не помогло (и я своими силами не справился), я с этими ошибками иду: или к разработке, или в аварийную конференцию.
         - Собираю всех разрабов и админов вместе в одной конфе.

- Подготовка и внедрение релизов через CI/CD-пайплайны совместно с администраторами:
   - К примеру вы готовили задачи в Jira, заполняли необходимые поля и планировали работы.
      - Дата проведения, какие команды, соответствующие документы и согласования если нужны
   - Вы написали конфиг Nginx на балансировку x3 Mimir (будет ниже), описывали последовательность шагов в документации ко внедрению и на совместной встрече с администраторами раскатывали этот конфиг через джобу Teamcity/Jenkins (вы просто должны знать, что Teamcity - это инструмент CI/CD, но на собеседовании можете говорить о нём смело, что за раскатку уже отвечали админы). Внимание! На вашем рабочем проекте может быть только один инструмент: или это Teamcity или это только Jenkins, если же вы оговорились в процессе собеседования, то смело вбрасываем собеседующим, что вы работаете на платформе DEV - это среда и сопровождение отдела по разработке и у вас были развязаны руки и вы ставили, что хотели, какое угодно ПО, и у вас был Teamcity, а у администраторов на ПРОД-контуре был Jenkins - всё просто.
- Взаимодействие с разработчиками для устранения проблем в коде.
   - К примеру разбираем почему произошли ошибки 502 и 503.
   - Разработчики открывают исходный код приложения и начинают погружаться в суть.
   - Кстати, спросит собеседующий, а на каком языке у вас написан бэк?
      - Отвечаем Java и Kotlin, но в вашем сопровождении только приложения Java, из них 20 микросервисов (адаптертов), отвечающих за:
      - Документы
      - Биллинг
      - Прокси
      - Калькулятор (если кредиты)
      - И так далее

- Участие в конференциях (во встречах) по оптимизации инфраструктуры.
   - Еженедельные встречи где выступают тимлиды от всех команд: админы, разработка, сопровождение.
   - Там регулярно обсуждаются вопросы об улучшении нашей платформы. 
- В процессе вашего рассказа по распорядку или в любой неудобный момент вам могут задать пару вопросов:
   - Вброс от собеседующего. Например, расскажи какая была самая простая задача и какая самая сложная?
      - **Простая**. Установка Node Exporter, ставил сам на нужные сервера (всегда стараемся отвечать подробно, чтобы из вас не выдавливал собеседующий доп.вопросы).
         - Как устанавливал? Вручную на каждую VM тачку нашего отдела или Bash скриптом.
            - Как запускал скрипт? Дал ему `chmod +x` права и запустил через `./bash-script.sh`
            - Расскажи про состав скрипта (эту формулу используем для любого bash скрипта на собеседовании)?
               - Скрипт представлял из себя тело, где был перебор последовательных команд:
                  - Взять архив с бинарём из Nexus (наша файловая шара) по ссылке
                  - Положить в `/tmp`, далее разархивировать его
                  - Далее поставить `.bin` на автозапуск и запустить его
                     - Как будешь ставить?
                     - Пропишу юнит-файл на запуск Node Exporter в `systemd`
                     - Перечитаю директорию systemd на новый юнит-файл Node Exporter командой `sudo systemctl daemon-reload`
                     - Запущу Node Exporter командой `sudo systemctl start node.exporter`
                     - Поставлю на автозапуск командой `sudo systemctl enable node.exporter`
                     - Проверю Node Exporter на веб-морде на порту :9100
                     - Пропишу в конфиге Prometheus таргет Node Exporter и проверю метрики экспортера на веб-морде Prometheus на порту :9090

      - **Сложная**. Балансировка нагрузки на Nginx совместно с администраторами.
         - Как балансировал (по какому алгоритму)? Что именно балансировал (какие серверы?)? Что такое round-robin (хотят услышать определение алгоритма)? Какие директивы и блоки использовал (хотят услышать построчно конфиг)? 
            - Я написал nginx.conf файл для балансировки по алгоритму round-robin (запросы распределяются между серверами последовательно: каждый новый запрос отправляется на следующий сервер в списке).
            - Далее диктуем собеседующему построчно:
            ```yaml
            # Определение группы серверов с именем "backend" для балансировки нагрузки
            upstream backend { # Блок (контейнер для серверов)

                # Первый сервер в группе (будет получать запросы при балансировке)
                server backend1.example.com; # Директива внутри блока upstream
                
                # Второй сервер в группе
                server backend2.example.com; # Директива внутри блока upstream
                
                # Третий сервер в группе
                server backend3.example.com; # Директива внутри блока upstream
            }
            
            # Конфигурация виртуального сервера (блока server)
            server { # Блок виртуального хоста
                # Указание порта (80) для прослушивания входящих соединений
                listen 80; # Директива
                
                # Имя сервера, для которого обрабатываются запросы
                server_name app.example.com; # Директива
                
                # Блок location для обработки запросов по пути "/" (все запросы)
                location / { # Блок для обработки URL-путей
                    # Перенаправление всех запросов на группу серверов "backend"
                    proxy_pass http://backend; # Директива
                }
            }
            ```
            - А также можете продиктовать следующее. Расшифровка конфига Nginx:            
               1. `upstream` - определяет группу серверов для балансировки нагрузки
               2. По умолчанию используется алгоритм Round Robin (по очереди)
               3. `server` блок обрабатывает запросы для указанного домена
               4. `location /` - обрабатывает все пути, начинающиеся с /
               5. `proxy_pass` - перенаправляет запросы на указанную группу серверов
               6. Эта конфигурация создает простой балансировщик нагрузки, который равномерно распределяет запросы между тремя бэкенд-серверами.

            - Какие директивы использовал и какие есть?
               - Указаны в конфиге выше
               - Кто писал конфиг?
                  - Я писал конфиг
               - Как запускал-применял конфиг?
                  - Перечитывал конфиг-файл Nginx командой `sudo systemctl reload nginx `
               - Как проверял запуск?
                  - Командой `sudo systemctl status nginx `
            - Что именно балансировал (какие серверы?) и почему?
               - Я балансировал серверы Mimir, их было три, это горизонатальное масштабирование Prometheus с помощью Nginx
               - Почему Mimir, а не федерация?
                  - Нам не хватало [производительности федерации](https://github.com/lamjob1993/linux-monitoring/blob/main/prometheus/beginning/9.2%20%D0%9C%D0%B0%D1%81%D1%88%D1%82%D0%B0%D0%B1%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5.md), поэтому решили перейти на Mimir

---

### 3. **Стек отдела**

Если на собеседовании вы чувствуете, что вас долбят вопросами по стеку, то отвечайте спокойно, что Terraform и Ansible вы использовали совместно с командой администраторов, писали конфиги, участвовали во внедрениях с помощью этих инструментов (если успеваете пройти эти инструменты по курсу, то отвечаем, что использовали вы сами). Потому что на данном этапе вы еще не работали с Docker, Terraform и Ansible и я это понимаю. Но в целом методология вполне рабочая и применимая.

Наш отдел использует следующий стек технологий (внимание, если вы указываете этот стек в резюме, то от каждого инструмента, даже если вы с ним работали поверхностно слова должны отскакивать, как от зубов, хотя бы в трех предложениях, как минимум, учитесь импровизировать на ходу):

**Мониторинг:**
- **Grafana**: Для визуализации метрик и создания дашбордов.
- **Prometheus**: Для сбора метрик с серверов и приложений.
- **Node Exporter**: Для мониторинга состояния серверов.
- **Blackbox Exporter**: Для проверки доступности сервисов (HTTP, TCP, ICMP).
- **Nginx Exporter**: Для мониторинга производительности Nginx.
- **Postgres Exporter**: Для мониторинга баз данных PostgreSQL.

**Серверы:**
- **Nginx**: Балансировка нагрузки и проксирование трафика.
- **Kubernetes (k8s)**: Оркестрация контейнеров.
- **OpenShift**: Платформа для управления контейнерами.

**Контроль версий:**
- **Git:** Система контроля версий, которая позволяет нескольким разработчикам одновременно работать над одним продуктом.
- **Bitbucket:** Веб-сервис для хостинга проектов и их совместной разработки, основанный на системе контроля версий Git.

**CI/CD:**
- **TeamCity**: Автоматизация сборки и тестирования.
- **Ansible**: Конфигурационное управление.
- **Docker**: Контейнеризация приложений.
- **Terraform**: Управление инфраструктурой как кодом.

**ОС:**
- **Debian**: Используется в разрезе стенда DEV в качестве песочницы.
- **CentOS**: Основная операционная система для серверов.

---

### 4. **Вопросы к каждому инструменту (это беглый, но рабочий формат, а более развернутый формат с кейсами будет внутри репозитория по ходу прохождения практики)**

#### **Debian/CentOS**
1. Как вы обновляли операционные системы?
   - Ответ: Использовал `apt` для Debian и `yum` для CentOS. Автоматизировал процесс через Ansible.

2. Как вы решали проблемы с зависимостями пакетов?
   - Ответ: Проверял логи и временно отключал конфликтующие пакеты.

3. Как вы мониторили состояние серверов?
   - Ответ: Использовал Node Exporter и настраивал алерты через Prometheus.

4. Как вы настраивали файрволы?
   - Ответ: Использовал `iptables` или `firewalld` в зависимости от ОС.

5. Как вы обеспечивали безопасность серверов?
   - Ответ: Регулярно обновлял системы, настраивал SELinux/AppArmor и ограничивал доступ по SSH.

---

#### **Grafana**
1. Как вы настраивали дашборды для мониторинга критических метрик?
   - Ответ: Я создавал дашборды, которые показывают использование CPU, RAM, дискового пространства и сетевой активности. Также добавлял графики для HTTP-статусов и времени отклика сервисов.

2. Как вы организовывали уведомления?
   - Ответ: Мы настроили алерты через Alertmanager, которые отправляют уведомления в Telegram и email, если метрики выходят за допустимые пределы.

3. Как вы решали проблемы с производительностью дашбордов?
   - Ответ: Оптимизировал запросы к Prometheus, уменьшая количество данных, которые нужно обрабатывать, и использовал агрегацию метрик.

4. Как вы интегрировали Grafana с другими инструментами?
   - Ответ: Мы интегрировали Grafana с Prometheus для сбора метрик и с Blackbox Exporter для мониторинга доступности сервисов.

5. Как вы обеспечивали безопасность дашбордов?
   - Ответ: Настроил RBAC (Role-Based Access Control), чтобы ограничить доступ к дашбордам только для авторизованных пользователей.

---

#### **Prometheus**
1. Как вы собирали метрики с серверов?
   - Ответ: Использовал Node Exporter для сбора метрик с серверов и настраивал scrape jobs в конфигурации Prometheus.

2. Как вы решали проблемы с нехваткой места для хранения метрик?
   - Ответ: Настроил retention policies и использовал компрессию данных для уменьшения объема хранимых метрик.

3. Как вы организовывали alerting?
   - Ответ: Создавал правила в Prometheus Rules для мониторинга критических метрик, таких как использование CPU выше 90% или недоступность сервисов.

4. Как вы решали проблемы с высокой нагрузкой на Prometheus?
   - Ответ: Добавлял больше серверов для шардинга данных и настраивал federation для распределенного сбора метрик.

5. Как вы тестировали новые правила алертинга?
   - Ответ: Использовал Prometheus Recording Rules для тестирования правил перед их применением в продакшене.

---

#### **Node Exporter**
1. Как вы собирали метрики с серверов?
   - Ответ: Использовал Node Exporter для сбора метрик, таких как использование CPU, RAM, дискового пространства и сетевой активности. Настроил его на всех серверах через Ansible.

2. Как вы решали проблемы с высоким потреблением ресурсов Node Exporter?
   - Ответ: Ограничивал частоту сбора данных и использовал фильтры для исключения ненужных метрик.

3. Как вы мониторили состояние Node Exporter?
   - Ответ: Добавлял метрики Node Exporter в Prometheus и создавал дашборды в Grafana для визуализации.

4. Как вы обновляли Node Exporter на серверах?
   - Ответ: Использовал Ansible для автоматического обновления версий Node Exporter на всех серверах.

5. Как вы решали проблемы с отсутствием данных от Node Exporter?
   - Ответ: Проверял логи Node Exporter, конфигурацию scrape jobs в Prometheus и статус сервиса на сервере.

---

#### **Blackbox Exporter**
1. Как вы проверяли доступность сервисов?
   - Ответ: Использовал Blackbox Exporter для проверки HTTP, TCP и ICMP. Настроил probes для каждого типа сервиса.

2. Как вы решали проблемы с ложными алертами от Blackbox Exporter?
   - Ответ: Настроил таймауты и пороговые значения для уменьшения количества ложных срабатываний.

3. Как вы интегрировали Blackbox Exporter с Prometheus?
   - Ответ: Добавил Blackbox Exporter как target в конфигурацию Prometheus и настроил соответствующие scrape jobs.

4. Как вы тестировали новые probes?
   - Ответ: Запускал тестовые probes в изолированной среде перед добавлением их в продакшен.

5. Как вы обеспечивали безопасность Blackbox Exporter?
   - Ответ: Ограничивал доступ к Blackbox Exporter через файрвол и использовал RBAC для управления доступом.

---

#### **Postgres Exporter**
1. Как вы собирали метрики с PostgreSQL?
   - Ответ: Использовал Postgres Exporter для сбора метрик, таких как количество подключений, время выполнения запросов и использование таблиц.

2. Как вы решали проблемы с производительностью базы данных?
   - Ответ: Анализировал метрики Postgres Exporter и оптимизировал запросы и индексы.

3. Как вы интегрировали Postgres Exporter с Prometheus?
   - Ответ: Настроил scrape jobs в Prometheus для сбора метрик с Postgres Exporter.

4. Как вы решали проблемы с отсутствием данных от Postgres Exporter?
   - Ответ: Проверял права доступа к базе данных и конфигурацию экспортера.

5. Как вы мониторили репликацию PostgreSQL?
   - Ответ: Добавлял метрики репликации в Postgres Exporter и настраивал алерты в Prometheus.

---

#### **Nginx**
1. Как была реализована балансировка нагрузки?
   - Ответ: Мы использовали Nginx с алгоритмом round-robin для равномерного распределения трафика между серверами.

2. Как вы решали проблемы с медленными ответами?
   - Ответ: Анализировал логи Nginx и оптимизировал конфигурацию keepalive и timeout.

3. Как вы настраивали мониторинг Nginx?
   - Ответ: Использовал Nginx Exporter для сбора метрик, таких как количество запросов, время отклика и ошибки.

4. Как вы обеспечивали безопасность Nginx?
   - Ответ: Настроил SSL/TLS, ограничил доступ по IP и использовал WAF для защиты от атак.

5. Как вы решали проблемы с падением Nginx?
   - Ответ: Анализировал логи и добавлял health checks для автоматического перезапуска.

---

#### **Docker**
1. Как вы управляли контейнерами в продакшене?
   - Ответ: Использовал Docker Compose для оркестрации контейнеров и настраивал health checks для мониторинга состояния.

2. Как вы решали проблемы с перезапуском контейнеров?
   - Ответ: Настроил restart policies и добавлял мониторинг через Docker Exporter.

3. Как вы оптимизировали использование ресурсов Docker?
   - Ответ: Ограничивал CPU и RAM для контейнеров через параметры запуска.

4. Как вы обновляли образы Docker?
   - Ответ: Использовал CI/CD-пайплайн для сборки новых образов и их автоматического деплоя.

5. Как вы решали проблемы с нехваткой места на диске?
   - Ответ: Очищал старые образы и volumes через команды `docker system prune`.

---

#### **Ansible**
1. Как вы автоматизировали развертывание серверов?
   - Ответ: Писал плейбуки Ansible для установки и настройки необходимых пакетов, конфигураций и сервисов.

2. Как вы решали проблемы с неудачными деплоями через Ansible?
   - Ответ: Проверял логи выполнения плейбуков и исправлял ошибки в конфигурации.

3. Как вы организовывали управление конфигурациями?
   - Ответ: Использовал роли и переменные Ansible для централизованного управления конфигурациями.

4. Как вы тестируете новые плейбуки?
   - Ответ: Запускал плейбуки в тестовой среде перед применением в продакшене.

5. Как вы обеспечивали безопасность при использовании Ansible?
   - Ответ: Использовал Vault для шифрования чувствительных данных и ограничивал доступ к репозиторию с плейбуками.

---

#### **Terraform**
1. Как вы управляли инфраструктурой через Terraform?
   - Ответ: Писал конфигурации Terraform для создания и управления серверами, сетями и другими ресурсами.

2. Как вы решали проблемы с конфликтами состояний (state conflicts)?
   - Ответ: Использовал remote state в S3 и настраивал блокировки через DynamoDB.

3. Как вы тестировали новые конфигурации Terraform?
   - Ответ: Запускал `terraform plan` для проверки изменений перед применением.

4. Как вы организовывали модульность Terraform?
   - Ответ: Создавал модули для повторного использования конфигураций.

5. Как вы обеспечивали безопасность Terraform?
   - Ответ: Шифровал чувствительные данные через `sensitive` и хранил state файлы в защищенном месте.

---

#### **Kubernetes-OpenShift - используйте, как синонимы**
1. Как вы решали проблемы с деплоем приложений?
   - Ответ: Проверял логи подов и настраивал readiness probes для корректного старта приложений.

2. Как вы мониторили состояние кластера?
   - Ответ: Использовал Prometheus для сбора метрик с kube-state-metrics и Grafana для визуализации.

3. Как вы решали проблемы с производительностью кластера?
   - Ответ: Оптимизировал использование ресурсов через resource requests и limits.

4. Как вы настраивали CI/CD для Kubernetes?
   - Ответ: Использовал TeamCity для сборки образов Docker и Helm для деплоя в Kubernetes.

5. Как вы решали проблемы с нехваткой ресурсов?
   - Ответ: Добавлял новые ноды в кластер и настраивал autoscaling.

---

#### **TeamCity/Jenkins - используйте, как синонимы**
1. Как вы настраивали пайплайны для сборки проектов?
   - Ответ: Использовал build steps для выполнения команд сборки, тестирования и деплоя.

2. Как вы решали проблемы с зависанием билдов?
   - Ответ: Анализировал логи и увеличивал таймауты для длительных задач.

3. Как вы организовывали уведомления о статусе билдов?
   - Ответ: Настроил интеграцию с Slack для отправки уведомлений о завершении билдов.

4. Как вы решали проблемы с нехваткой ресурсов агентов?
   - Ответ: Добавлял новые агенты и настраивал параллельное выполнение задач.

5. Как вы тестировали новые пайплайны?
   - Ответ: Запускал тестовые билды в отдельной ветке перед деплоем в продакшен.
